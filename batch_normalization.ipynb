{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import get_normalized_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weight(M1, M2):\n",
    "\treturn np.random.randn(M1, M2) * np.sqrt(2.0 / M1)\n",
    "\n",
    "\n",
    "class HiddenLayerBatchNorm(object):\n",
    "\tdef __init__(self, M1, M2, f):\n",
    "\t\tself.M1 = M1\n",
    "\t\tself.M2 = M2\n",
    "\t\tself.f = f\n",
    "\n",
    "\t\tW = init_weight(M1, M2).astype(np.float32)\n",
    "\t\tgamma = np.ones(M2).astype(np.float32)\n",
    "\t\tbeta = np.zeros(M2).astype(np.float32)\n",
    "\n",
    "\t\tself.W = tf.Variable(W)\n",
    "\t\tself.gamma = tf.Variable(gamma)\n",
    "\t\tself.beta = tf.Variable(beta)\n",
    "\n",
    "\t\t# for test time\n",
    "\t\tself.running_mean = tf.Variable(np.zeros(M2).astype(np.float32), trainable=False)\n",
    "\t\tself.running_var = tf.Variable(np.zeros(M2).astype(np.float32), trainable=False)\n",
    "\n",
    "\tdef forward(self, X, is_training, decay=0.9):\n",
    "\t\tactivation = tf.matmul(X, self.W)\n",
    "\t\tif is_training:\n",
    "\t\t\tbatch_mean, batch_var = tf.nn.moments(activation, [0])\n",
    "\t\t\tupdate_running_mean = tf.assign(\n",
    "\t\t\t\tself.running_mean,\n",
    "\t\t\t\tself.running_mean * decay + batch_mean * (1 - decay)\n",
    "\t\t\t)\n",
    "\t\t\tupdate_running_var = tf.assign(\n",
    "\t\t\t\tself.running_var,\n",
    "\t\t\t\tself.running_var * decay + batch_var * (1 - decay)\n",
    "\t\t\t)\n",
    "\t\t\t\n",
    "\t\t\twith tf.control_dependencies([update_running_mean, update_running_var]):\n",
    "\t\t\t\tout = tf.nn.batch_normalization(\n",
    "\t\t\t\t\tactivation,\n",
    "\t\t\t\t\tbatch_mean,\n",
    "\t\t\t\t\tbatch_var,\n",
    "\t\t\t\t\tself.beta,\n",
    "\t\t\t\t\tself.gamma,\n",
    "\t\t\t\t\t1e-4\n",
    "\t\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\tout = tf.nn.batch_normalization(\n",
    "\t\t\t\tactivation,\n",
    "\t\t\t\tself.running_mean,\n",
    "\t\t\t\tself.running_var,\n",
    "\t\t\t\tself.beta,\n",
    "\t\t\t\tself.gamma,\n",
    "\t\t\t\t1e-4\n",
    "\t\t\t)\n",
    "\t\treturn self.f(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(object):\n",
    "\tdef __init__(self, M1, M2, f):\n",
    "\t\tself.M1 = M1\n",
    "\t\tself.M2 = M2\n",
    "\t\tself.f = f\n",
    "\t\tW = np.random.randn(M1, M2) * np.sqrt(2.0 / M1)\n",
    "\t\tb = np.zeros(M2)\n",
    "\t\tself.W = tf.Variable(W.astype(np.float32))\n",
    "\t\tself.b = tf.Variable(b.astype(np.float32))\n",
    "\n",
    "\tdef forward(self, X):\n",
    "\t\treturn self.f(tf.matmul(X, self.W) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ANN(object):\n",
    "\tdef __init__(self, hidden_layer_sizes):\n",
    "\t\tself.hidden_layer_sizes = hidden_layer_sizes\n",
    "\n",
    "\tdef set_session(self, session):\n",
    "\t\tself.session = session\n",
    "\n",
    "\tdef fit(self, X, Y, Xtest, Ytest, activation=tf.nn.relu, learning_rate=1e-2, epochs=15, batch_sz=100, print_period=100, show_fig=True):\n",
    "\t\tX = X.astype(np.float32)\n",
    "\t\tY = Y.astype(np.int32)\n",
    "\n",
    "\t\t# initialize hidden layers\n",
    "\t\tN, D = X.shape\n",
    "\t\tself.layers = []\n",
    "\t\tM1 = D\n",
    "\t\tfor M2 in self.hidden_layer_sizes:\n",
    "\t\t\th = HiddenLayerBatchNorm(M1, M2, activation)\n",
    "\t\t\tself.layers.append(h)\n",
    "\t\t\tM1 = M2\n",
    "\t\t\t\n",
    "\t\t# final layer\n",
    "\t\tK = len(set(Y))\n",
    "\t\th = HiddenLayer(M1, K, lambda x: x)\n",
    "\t\tself.layers.append(h)\n",
    "\n",
    "\t\tif batch_sz is None:\n",
    "\t\t\tbatch_sz = N\n",
    "\n",
    "\n",
    "\t\t# note! we will need to build the output differently\n",
    "\t\t# for train and test (prediction)\n",
    "\n",
    "\t\t# set up theano functions and variables\n",
    "\t\ttfX = tf.placeholder(tf.float32, shape=(None, D), name='X')\n",
    "\t\ttfY = tf.placeholder(tf.int32, shape=(None,), name='Y')\n",
    "\n",
    "\t\t# for later use\n",
    "\t\tself.tfX = tfX\n",
    "\n",
    "\t\t# for training\n",
    "\t\tlogits = self.forward(tfX, is_training=True)\n",
    "\t\tcost = tf.reduce_mean(\n",
    "\t\t\ttf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "\t\t\t\tlogits=logits,\n",
    "\t\t\t\tlabels=tfY\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\t\t# train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\t\t# train_op = tf.train.RMSPropOptimizer(learning_rate, decay=0.99, momentum=0.9).minimize(cost)\n",
    "\t\ttrain_op = tf.train.MomentumOptimizer(learning_rate, momentum=0.9, use_nesterov=True).minimize(cost)\n",
    "\t\t# train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "\t\t# for testing\n",
    "\t\ttest_logits = self.forward(tfX, is_training=False)\n",
    "\t\tself.predict_op = tf.argmax(test_logits, 1)\n",
    "\n",
    "\t\t# accuracy = tf.reduce_mean(1.0*(tfY == tf.argmax(logits, 1)))\n",
    "\n",
    "\t\t# init the variables\n",
    "\t\tself.session.run(tf.global_variables_initializer())\n",
    "\n",
    "\t\tn_batches = N // batch_sz\n",
    "\t\tcosts = []\n",
    "\t\tfor i in range(epochs):\n",
    "\t\t\tif n_batches > 1:\n",
    "\t\t\t\tX, Y = shuffle(X, Y)\n",
    "\t\t\tfor j in range(n_batches):\n",
    "\t\t\t\tXbatch = X[j*batch_sz:(j*batch_sz+batch_sz)]\n",
    "\t\t\t\tYbatch = Y[j*batch_sz:(j*batch_sz+batch_sz)]\n",
    "\n",
    "\t\t\t\tc, _, lgts = self.session.run([cost, train_op, logits], feed_dict={tfX: Xbatch, tfY: Ybatch})\n",
    "\t\t\t\tcosts.append(c)\n",
    "\t\t\t\tif (j+1) % print_period == 0:\n",
    "\t\t\t\t\tacc = np.mean(Ybatch == np.argmax(lgts, axis=1))\n",
    "\t\t\t\t\tprint(\"epoch:\", i, \"batch:\", j, \"n_batches:\", n_batches, \"cost:\", c, \"acc: %.2f\" % acc)\n",
    "\t\t\t\t\t# print('dbg:', self.session.run(self.layers[0].running_mean).sum())\n",
    "\n",
    "\t\t\tprint(\"Train acc:\", self.score(X, Y), \"Test acc:\", self.score(Xtest, Ytest))\n",
    "\t\t\n",
    "\t\tif show_fig:\n",
    "\t\t\tplt.plot(costs)\n",
    "\t\t\tplt.show()\n",
    "\n",
    "\tdef forward(self, X, is_training):\n",
    "\t\tout = X\n",
    "\t\tfor h in self.layers[:-1]:\n",
    "\t\t\tout = h.forward(out, is_training)\n",
    "\t\tout = self.layers[-1].forward(out)\n",
    "\t\treturn out\n",
    "\n",
    "\tdef score(self, X, Y):\n",
    "\t\tP = self.predict(X)\n",
    "\t\treturn np.mean(Y == P)\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\t\treturn self.session.run(self.predict_op, feed_dict={self.tfX: X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n",
      "epoch: 0 batch: 99 n_batches: 410 cost: 0.515462 acc: 0.86\n",
      "epoch: 0 batch: 199 n_batches: 410 cost: 0.245739 acc: 0.93\n",
      "epoch: 0 batch: 299 n_batches: 410 cost: 0.221408 acc: 0.95\n",
      "epoch: 0 batch: 399 n_batches: 410 cost: 0.144711 acc: 0.96\n",
      "Train acc: 0.962268292683 Test acc: 0.946\n",
      "epoch: 1 batch: 99 n_batches: 410 cost: 0.129652 acc: 0.97\n",
      "epoch: 1 batch: 199 n_batches: 410 cost: 0.103494 acc: 0.97\n",
      "epoch: 1 batch: 299 n_batches: 410 cost: 0.124998 acc: 0.98\n",
      "epoch: 1 batch: 399 n_batches: 410 cost: 0.114213 acc: 0.99\n",
      "Train acc: 0.979585365854 Test acc: 0.955\n",
      "epoch: 2 batch: 99 n_batches: 410 cost: 0.0672628 acc: 0.99\n",
      "epoch: 2 batch: 199 n_batches: 410 cost: 0.0502289 acc: 0.99\n",
      "epoch: 2 batch: 299 n_batches: 410 cost: 0.110449 acc: 0.97\n",
      "epoch: 2 batch: 399 n_batches: 410 cost: 0.082089 acc: 0.99\n",
      "Train acc: 0.987 Test acc: 0.955\n",
      "epoch: 3 batch: 99 n_batches: 410 cost: 0.0672467 acc: 0.97\n",
      "epoch: 3 batch: 199 n_batches: 410 cost: 0.0535344 acc: 0.99\n",
      "epoch: 3 batch: 299 n_batches: 410 cost: 0.0478646 acc: 0.98\n",
      "epoch: 3 batch: 399 n_batches: 410 cost: 0.0776554 acc: 0.99\n",
      "Train acc: 0.992756097561 Test acc: 0.96\n",
      "epoch: 4 batch: 99 n_batches: 410 cost: 0.0322101 acc: 0.99\n",
      "epoch: 4 batch: 199 n_batches: 410 cost: 0.0301498 acc: 1.00\n",
      "epoch: 4 batch: 299 n_batches: 410 cost: 0.0728889 acc: 0.98\n",
      "epoch: 4 batch: 399 n_batches: 410 cost: 0.0453889 acc: 0.98\n",
      "Train acc: 0.995414634146 Test acc: 0.959\n",
      "epoch: 5 batch: 99 n_batches: 410 cost: 0.0596059 acc: 0.98\n",
      "epoch: 5 batch: 199 n_batches: 410 cost: 0.0121743 acc: 1.00\n",
      "epoch: 5 batch: 299 n_batches: 410 cost: 0.0444632 acc: 0.99\n",
      "epoch: 5 batch: 399 n_batches: 410 cost: 0.0497924 acc: 0.98\n",
      "Train acc: 0.997658536585 Test acc: 0.97\n",
      "epoch: 6 batch: 99 n_batches: 410 cost: 0.0323632 acc: 0.99\n",
      "epoch: 6 batch: 199 n_batches: 410 cost: 0.0248738 acc: 0.99\n",
      "epoch: 6 batch: 299 n_batches: 410 cost: 0.0348322 acc: 0.98\n",
      "epoch: 6 batch: 399 n_batches: 410 cost: 0.0356054 acc: 0.98\n",
      "Train acc: 0.998390243902 Test acc: 0.97\n",
      "epoch: 7 batch: 99 n_batches: 410 cost: 0.00712362 acc: 1.00\n",
      "epoch: 7 batch: 199 n_batches: 410 cost: 0.0180616 acc: 0.99\n",
      "epoch: 7 batch: 299 n_batches: 410 cost: 0.0106774 acc: 1.00\n",
      "epoch: 7 batch: 399 n_batches: 410 cost: 0.0199706 acc: 1.00\n",
      "Train acc: 0.999048780488 Test acc: 0.97\n",
      "epoch: 8 batch: 99 n_batches: 410 cost: 0.029921 acc: 0.99\n",
      "epoch: 8 batch: 199 n_batches: 410 cost: 0.0157777 acc: 1.00\n",
      "epoch: 8 batch: 299 n_batches: 410 cost: 0.016456 acc: 1.00\n",
      "epoch: 8 batch: 399 n_batches: 410 cost: 0.0103988 acc: 1.00\n",
      "Train acc: 0.999487804878 Test acc: 0.967\n",
      "epoch: 9 batch: 99 n_batches: 410 cost: 0.0219393 acc: 0.99\n",
      "epoch: 9 batch: 199 n_batches: 410 cost: 0.019479 acc: 0.99\n",
      "epoch: 9 batch: 299 n_batches: 410 cost: 0.0451051 acc: 0.98\n",
      "epoch: 9 batch: 399 n_batches: 410 cost: 0.0256879 acc: 0.99\n",
      "Train acc: 0.999707317073 Test acc: 0.966\n",
      "epoch: 10 batch: 99 n_batches: 410 cost: 0.00752255 acc: 1.00\n",
      "epoch: 10 batch: 199 n_batches: 410 cost: 0.00926216 acc: 1.00\n",
      "epoch: 10 batch: 299 n_batches: 410 cost: 0.0115579 acc: 1.00\n",
      "epoch: 10 batch: 399 n_batches: 410 cost: 0.00793105 acc: 1.00\n",
      "Train acc: 0.99987804878 Test acc: 0.967\n",
      "epoch: 11 batch: 99 n_batches: 410 cost: 0.00634661 acc: 1.00\n",
      "epoch: 11 batch: 199 n_batches: 410 cost: 0.00694104 acc: 1.00\n",
      "epoch: 11 batch: 299 n_batches: 410 cost: 0.00969311 acc: 1.00\n",
      "epoch: 11 batch: 399 n_batches: 410 cost: 0.00713461 acc: 1.00\n",
      "Train acc: 0.999853658537 Test acc: 0.97\n",
      "epoch: 12 batch: 99 n_batches: 410 cost: 0.0111236 acc: 1.00\n",
      "epoch: 12 batch: 199 n_batches: 410 cost: 0.00933954 acc: 1.00\n",
      "epoch: 12 batch: 299 n_batches: 410 cost: 0.00840268 acc: 1.00\n",
      "epoch: 12 batch: 399 n_batches: 410 cost: 0.00872352 acc: 1.00\n",
      "Train acc: 0.999902439024 Test acc: 0.969\n",
      "epoch: 13 batch: 99 n_batches: 410 cost: 0.00572152 acc: 1.00\n",
      "epoch: 13 batch: 199 n_batches: 410 cost: 0.00535661 acc: 1.00\n",
      "epoch: 13 batch: 299 n_batches: 410 cost: 0.00303798 acc: 1.00\n",
      "epoch: 13 batch: 399 n_batches: 410 cost: 0.0197381 acc: 0.99\n",
      "Train acc: 0.999902439024 Test acc: 0.969\n",
      "epoch: 14 batch: 99 n_batches: 410 cost: 0.00417502 acc: 1.00\n",
      "epoch: 14 batch: 199 n_batches: 410 cost: 0.00638381 acc: 1.00\n",
      "epoch: 14 batch: 299 n_batches: 410 cost: 0.00658001 acc: 1.00\n",
      "epoch: 14 batch: 399 n_batches: 410 cost: 0.00887781 acc: 1.00\n",
      "Train acc: 0.99987804878 Test acc: 0.968\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAH9VJREFUeJzt3Xl8VPW9//HXJwu7bEIR2QKWqlAX\nkKIUrfx6a1W0+mtrK/7urV5bH16X7u1twQVrq1Vrf261Vblqta1a6k4FRUAobixhX8IuSyCQECAJ\nWUgy+d4/5iRMwiwJmWTmHN/PxyOPmTlzcs7nC8N7Dt/zPd9jzjlERCRYMlJdgIiIJJ/CXUQkgBTu\nIiIBpHAXEQkghbuISAAp3EVEAkjhLiISQAp3EZEAUriLiARQVqp23KdPH5eTk5Oq3YuI+NKyZcv2\nO+f6JlovZeGek5NDbm5uqnYvIuJLZrajOeupW0ZEJIAU7iIiAaRwFxEJIIW7iEgAKdxFRAJI4S4i\nEkAKdxGRAPJduG/cW8ZD725k/+EjqS5FRCRt+S7cNxeW8dh7WzhQXp3qUkRE0pbvwt0wAHRfbxGR\n2PwX7uFsx6F0FxGJxXfhnlEf7sp2EZGYfBfueN0ydUp3EZGYEoa7mQ0ys/lmlmdm68zsR1HWmWBm\nJWa20vuZ2jblRnTLKNtFRGJqzpS/tcDPnHPLzewEYJmZzXHOrW+y3vvOucuTX2Jj1tY7EBEJgIRH\n7s65Aufccu95GZAHDGjrwmIx02gZEZFEWtTnbmY5wChgcZS3x5nZKjN728xGJqG26DV4jxotIyIS\nW7PvxGRm3YBXgR8750qbvL0cGOKcO2xmE4E3gOFRtnEjcCPA4MGDj6tg9bmLiCTWrCN3M8smHOwv\nOOdea/q+c67UOXfYez4LyDazPlHWm+acG+OcG9O3b8JbAMaoxdvWcf22iMinQ3NGyxjwDJDnnHso\nxjoneethZmO97RYns9CIfQEaCikiEk9zumXGA98B1pjZSm/ZbcBgAOfck8BVwM1mVgtUApOca5v0\nbehzV7aLiMSUMNydcx+QYASic+5x4PFkFRVP/ZG7OmZERGLz3RWqOnIXEUnMf+GuE6oiIgn5L9w1\n5a+ISEL+C/eGce5KdxGRWPwb7qktQ0Qkrfkv3DXlr4hIQv4Ld42EFBFJyH/h7j0q20VEYvNfuGvK\nXxGRhHwY7uFHTfkrIhKb/8Lde9SRu4hIbP4Ldw2FFBFJyIfhXt/nrngXEYnFf+HuPSrbRURi81+4\n1x+5q2NGRCQm/4W796gjdxGR2PwX7rpBtohIQv4L9/opf1Nch4hIOvNfuGvKXxGRhHwX7vUU7SIi\nsfku3DM0t4yISEK+C3d1y4iIJObfcE9tGSIiac1/4a4bZIuIJOS/cNeUvyIiCfkv3L1HHbmLiMTm\nv3BXn7uISEI+DHdN+Ssikoj/wt17VLaLiMSWMNzNbJCZzTezPDNbZ2Y/irKOmdljZrbFzFab2ei2\nKVdT/oqINEdWM9apBX7mnFtuZicAy8xsjnNufcQ6lwLDvZ9zgSe8x6TTkbuISGIJj9ydcwXOueXe\n8zIgDxjQZLUrgb+4sEVATzPrn/Rq0ZS/IiLN0aI+dzPLAUYBi5u8NQDYFfE6n2O/AJJCU/6KiCTW\n7HA3s27Aq8CPnXOlTd+O8ivH5K+Z3WhmuWaWW1RU1LJKG7bhbVyH7iIiMTUr3M0sm3Cwv+Ccey3K\nKvnAoIjXA4E9TVdyzk1zzo1xzo3p27fv8dR7dFut+m0RkWBrzmgZA54B8pxzD8VYbQZwrTdq5jyg\nxDlXkMQ6G2Rk6ComEZFEmjNaZjzwHWCNma30lt0GDAZwzj0JzAImAluACuD65JcaVt//U6duGRGR\nmBKGu3PuA6L3qUeu44Bbk1VUPJp+QEQkMR9eoaopf0VEEvFfuGvKXxGRhPwX7t6jjtxFRGLzXbij\nPncRkYR8F+6G5h8QEUnEd+GuYe4iIon5Ltzrp/ytq1O8i4jE4r9w9x4V7SIisfkv3NXlLiKSkP/C\nXVP+iogk5LtwR1P+iogk5Ltwt7iz3IiICPgx3L1HHbiLiMTmu3DPqB8KqXQXEYnJd+GuKX9FRBLz\nX7hryl8RkYT8F+6a8ldEJCHfhXs9HbmLiMTmu3DXUEgRkcT8F+4Nfe46dBcRicV34Z6huWVERBLy\nXbg3TPmrcBcRicl/4e49arSMiEhs/gt3dcuIiCTkw3DXlL8iIon4Ltwb6NBdRCQmX4a7mY7cRUTi\n8We4owN3EZF4fBnuGWYaLSMiEkfCcDezZ82s0MzWxnh/gpmVmNlK72dq8stsuk+NcxcRiSerGes8\nBzwO/CXOOu875y5PSkXNYJi6ZURE4kh45O6cWwgcaIdams90EZOISDzJ6nMfZ2arzOxtMxsZayUz\nu9HMcs0st6io6Lh3ZqDhMiIicSQj3JcDQ5xzZwF/AN6ItaJzbppzboxzbkzfvn2Pe4caCikiEl+r\nw905V+qcO+w9nwVkm1mfVlcWR7jPXfEuIhJLq8PdzE4yb04AMxvrbbO4tduNv0+NcxcRiSfhaBkz\newmYAPQxs3zgLiAbwDn3JHAVcLOZ1QKVwCTXxofV4XHuIiISS8Jwd85dk+D9xwkPlWw3BtTp0F1E\nJCZfXqGKumVEROLyZbjrHtkiIvH5M9xNo2VEROLxabhrnLuISDz+DHfU5y4iEo8vw11T/oqIxOfL\ncNeUvyIi8fky3NGUvyIicfky3E3TQoqIxOXPcEcnVEVE4vFnuOsKVRGRuPwZ7mi0jIhIPP4Mdx25\ni4jE5ctw15S/IiLx+TLcQVP+iojE48twN0MjIUVE4vBtuCvbRURi82e46wbZIiJx+TPcdeQuIhKX\nP8MdDYUUEYnHl+G+r/QIO4rLU12GiEja8mW4V9aEWJVfkuoyRETSli/DXURE4lO4i4gEkMJdRCSA\nFO4iIgGkcBcRCSCFu4hIACncRUQCKGG4m9mzZlZoZmtjvG9m9piZbTGz1WY2OvlliohISzTnyP05\n4JI4718KDPd+bgSeaH1ZIiLSGgnD3Tm3EDgQZ5Urgb+4sEVATzPrn6wCRUSk5ZLR5z4A2BXxOt9b\ndgwzu9HMcs0st6ioKAm7FhGRaJIR7hZlWdQ5G51z05xzY5xzY/r27dvqHa/fU9rqbYiIBFEywj0f\nGBTxeiCwJwnbTehIbag9diMi4jvJCPcZwLXeqJnzgBLnXEEStisiIscpK9EKZvYSMAHoY2b5wF1A\nNoBz7klgFjAR2AJUANe3VbEiItI8CcPdOXdNgvcdcGvSKmoBs2jd/SIioitURUQCSOEuIhJACncR\nkQDydbirx11EJDpfh7uIiESncBcRCSCFu4hIAPk63EMu6hQ2IiKfer4O92/86aNUlyAikpZ8He4i\nIhKdwl1EJIAU7iIiAaRwFxEJIIW7iEgAKdxFRAJI4S4iEkAKdxGRAFK4i4gEkMJdRCSAFO4iIgHk\ny3C/7xtnpLoEEZG05stw75Dpy7JFRNqNUlJEJIB8Ge6Rs7g/8M4GDpZXp6wWEZF05Mtwj/TEgq3c\n/c91qS5DRCSt+D7cAapDdakuQUQkrfgy3Ot0ez0Rkbh8Ge4o20VE4mpWuJvZJWa20cy2mNnkKO//\np5kVmdlK7+eG5Jd6VJeOmW25eRER30sY7maWCfwRuBQYAVxjZiOirDrdOXe29/N0kutsZOLn+zeu\nEWt4vqXwMNc+u4SqmlBbliAiktaac+Q+FtjinNvmnKsG/g5c2bZlxZeRYY1eL9pWzE//sZJQneMr\nD/2LhZuKWLr9QIqqExFJveaE+wBgV8TrfG9ZU980s9Vm9oqZDUpKdc1UXF7Na8t3s+tARXvuVkQk\nbTUn3C3KsqanNP8J5DjnzgTmAs9H3ZDZjWaWa2a5RUVFLatURESarTnhng9EHokPBPZEruCcK3bO\nHfFe/g9wTrQNOeemOefGOOfG9O3b93jqbTaL+p0kIvLp0JxwXwoMN7OhZtYBmATMiFzBzCLPcF4B\n5CWvRBERaamsRCs452rN7PvAbCATeNY5t87Mfg3kOudmAD80syuAWuAA8J9tWHNME36/IBW7FRFJ\nOwnDHcA5NwuY1WTZ1IjnU4ApyS2tdXJ3HGBQ784MObErCzcV0a1TFqMH90p1WSIi7cKfV6g2wyNz\nN3PhgwsAuPbZJXzjTx81vLdoW7HGwYtIoAU23OsVHz7S6PWO4nImTVvEba+vSVFFIiJtr1ndMn52\nzj1zG54v2lZM1w7hJm/cW5aqkkRE2lzgj9wjTZq2iEqvO0YTS4pIkH2qwh3g20993Krfr6oJMWtN\nQZKqERFpG74N90cnnd2q319fUMoljyykoKSyRb/367fWc8sLy1m2Q3PXiEj68m24X3l2tOltWmbD\n3jImeCNqmiv/YPjLoKyqttX7FxFpK74N92Q5UlvX6Abbzjk27Yt9stV5nfVmmt5AJFLx4SMcqdUQ\n43TxqQ93gIWbj05i9ury3Xz14YXM31gYdd36E7GK9k+PsqoarnriI7bvL091KQmt2nWInMkzWb+n\ntN33fc49c7npr8vafb8SncIdmLN+X8NFTfX/KLYWHo77Ozpw//SYl1dI7o6DPDx3U6pLSeiddXsB\nYh6ctLX5GzXba7rwdbiPHdo7Kdt5a3UBv35rfcL1Fm8r5oMt+wH4zjNLeHPl7qTsPx2t3V3ChAfn\nU1JZk+pSROQ4+DrcO2Qmr/ydxYlv9PHysvxGr3/095WUVgUz/B6Zu5ntxRUs3lac6lJE5Dj4OtyT\naX+TaQrumXl01uL5Gwr57nNLeaVJuAP86KUVbV6biEhL+Trcp0w8LWnb2rC3jJzJM3n2w08altXV\nOZxzXP/cUt7bEL0Pc0dxBe9t2EeoTpe8ikj68HW4jzy5B3/699Fttv1ht83i4kcWxl1n2/5yvvtc\nLk/+a2vDsro6d0zY14Tqmr3fTfvKuOqJjyg/ksqx9PqyEvEzX4c7wMQz+ideqRU27Ys/aqZe/cVN\nABc9/C+G3350+vt1e0oYfvvbvJy7K9qvUlJZ02is/QNvbyB3x8GGk7fJ1nSmTInPteEX3fMfbecR\nH4zCEf/xfbgD3HD+0FSXAEDO5JnkTJ7J1qJyIg/cL3vsAwBmxpiT5qy732XUb+Y0vK4fZnnnG2uT\nXuPKXYc45565vLEi0UgfjfVsD3fNWMcjczenugwJoECE+00TTkl1Cby0ZOcxy3YfqmRHccsvfKkO\nhb8ZCstafoR99VMf88A7G2K+n1cQHse/KOEoGHXL1NPN1sWPAjGfe59uHVNdQlTj73+v0eumEVEb\nqiMrynDO47kSsqomRF5BKYs/OcDiTw7wy0uSc7JZ0yxIKnyyv5yhfbqmugxfC0S4+8X7m/ezYudB\n7nxzLVU1dWwpPMzUy0c0vD996U6G9e3GzgNHx9xPeW0NY4b04jPdOzL+lD5U1Ybo0qHxX9vibcVc\n9+clVNVEP2kbqnO8tXoPXzvz5BbPY+9aMfF9yBttFO0LTCSWWWsKuOWF5Tx97Ri+MqJfqsvxLYV7\nO6qtc3w94l6uQKMrY3/56rG3/ntpyc6GLp/rx+fw5w+3s/GeS+iYldmwztXTFsXd7ym3hU/uHokI\n/2gH5GVVNVTX1nFit44ko8/9isc/YN2eUrbff1mrt5VKbXlCVY61bk8JABv2lqYs3HcUl5OVmcGA\nnp1Tsv9kCMwh1ZRLw90Qr948LsWVtJ1XcsMXUcU6Qo8mcmTML15dTf7B2FfiXvC7+RG3JYwdaI/O\n3UzO5JkNr0N1Luo0BetSMHmVSDJc+OCCY7pV/SYw4f5fF57C9vsv45whyZlvJp3d9eZathbFH6L5\n7ac+pqCkkmv+p/FR/Z8WhMfjRx7Fb9hbyouLd3KoIhzQkdO2llbV8tbqPY22UT+BVs7kmcxcXcC9\nM/M46+53qajWHPeppjMkbe8fubsoqUj/aUfULeNDb6zcw+r8Et77+QQKS6uirrPkkwOMuy/2kcdr\nK3bz/84dzKjBvbjkkfcbvXfqHe80PP/5y6sAOGNAD4aceOwJrr8t2sHmwvD89+VHjj0fUK+iupY/\nf7id//rSMPXBS7Ok432O8wpK+cUrq3n39L08fd0XUl1OXIH8V3bduCEAfHP0wKjvjx3amxO7dmjP\nkpKiLOKK1W37y/nBSysY+9t5x729q578uKE/PpHKmhDTl+5k1a5DjZZHdsfE65t+6N1NPDh7I2+s\n3BNzHYB/LN1FzuSZaXXTBw2FTOx4T7w759jX5AClrf6866f1TsY25uYVpv29lAMZ7rdddjrTbzyP\n///tsxpNC3zB8D4AdMzKYN7PLkxVeUnzz1XxgzKZNhSU8ctX13DlHz9stHx9QSn7D1c3Wra3pIo9\nh45esVtVE6K8OvyP4khtiHfW7uVQRTVT31zb6MpcCJ8XABq6iFrjSG2oRdM+tLWH52zi+Y+2p7qM\ntPLMB59w7m/nsSXB/RNaa/nOg5x25ztJnef+lheWJ21bbSGQ4d4xK5Nzh50IwB+uGcUvLjmV9352\nId+LuJK1Z5cO9OicDcDXzjo5JXX6yY+nr0y4zn2zNvDg7A2cd988vhhxMuq0O99pOLG7fk8pN/1t\nGWf/eg5/+XgHo34zh9teX0P5kVqqa48G8R1vHBv8EP6i+Gjrfu56c23Uo8VbX1xOzuSZHD5Sy6l3\nvMPER9+nqiZEzuSZXPvskuNp+jE+2V/O7HV7Wbip8Y0pDlVUc9+svJhfKI/O28xdM9YlpYZ0c7xd\nKO9vDk+xsSvOif7m+r73dx/Nsu0HAfhwc9tM6ZGOAt/n3q97J26Z8FkADnvdGvUXR3w4+cus3HmI\n84f3adej4KB6Pc6UBu+u3wfAC4uPvZL3xcU7ebHJ8jnr9zFq/ZxGwyhfX5HPT6avanj95dP7sWzH\nQa7/Yg4h58jKMGauDv9X+fN3zQZgc+FhTrszfA5h4aYiqmpCdMoODyM977fzuOGCoXz7C4PIMKNb\nx/A/h5mrC6gJ1fGlz/UFjnY3vblyD3dePoL/8/sFDTVE1vebt/J4dXk+Zw7syWVntmzOo5dzd/Gt\nMYNa9DvpoKK6llCdi3mupT29tTq9u0naW+r/RtrRmQN78vx3x3LesHBXTbeOWZzvddVIenp7TQGX\nepPDRQY7wHXekfhj85o/N8uKnYc4b1hvzIy9pVXcMzOv0dz92++/jFtfbPzf7YevPqvh+a/iHHnX\n98dGO/ewYe/RYaF7DlXy4+krufuKkQ3L/vuV1RyqqOH68TktPuFcfPgINSHH8p0HmeN9iVZWhwjV\nOTIz2vZ8wfkPzOdAeTVbfzvxuH7/X5vS67Z8ZVU11ISO/v2t3V3CkdqQL0fhNSvczewS4FEgE3ja\nOXd/k/c7An8BzgGKgaudc9uTW2pyXOgdjcXTITODp649hxcW7WBuXiG/+toIfvXP8MVGT/7HOfxu\n9ga2FTWeIuDNW8cf0x8trXdzkvs164eG/vP750d9P9p/6yO/VJoeHd7wfC69umSTmWENE8P9ZPpK\nnvngE9bkl1AbZZ7/+i6rSx9tPErp3ll53Dsrj5dvGsfibcVcPPIkLnr46JTTt088nbFDe/PBlv0M\n69OVMTm96d21Q8S1CUc9Pn8Lew5VcuflI9hTUsnIk3sAcLC8mg5ZGXTt2LLjuoPl1VSH6ujXvRPO\nuYYvjgNe11nTLrJ9pVU8sWAr/33xqdTWObp3ymL2ur2c1KMzZw/q2aJ9O+eY+uY6Rg/pSZ9uHTmp\neyeG9zuh4f3q2rqo3TrOOTbuK+O0k7rH3f6+0iqyMzPo3bUD5z/Q+NaSl/8hPOlf/f/QmjMdxw9f\nWsFFI/qlvLvXEp3lNrNMYBNwEZAPLAWucc6tj1jnFuBM59xNZjYJ+Lpz7up42x0zZozLzc1tbf1J\nc+odb1PrzcP+8NVn8fVR4ZE2a3eXMPLk7izfeZCBvbrQr3snqmvr+I+nF5NXUMpDV59NnXNcPPIk\nIPyBmrZwG18fPYCx987j5B6dGJPTmxmt6Pb5Qk4vlnp9hiLJNKBnZ3ZHnPwGuP8bZzBzTQG7D1Yy\nZeLpTF+6i7l54f8RXDyyH9v3V7BxXxmf69ct6pTYL9xwLj98aQXFUc6ZRLrn/36eOyJmPl39q6+y\n+2Blw5feTy/6HA/NiT4d8qqpX6WgtJLnP9pxzKR9K6dexGPztjTceOev3xvLhoIy7p2Vx5kDe3DF\nWSdzQqcsBvbqwsBenbnwwQXx/5CAN24dz8NzNtG1Yyaz1uxtWP7qzV/knCG9gKNfcEOnhEegbfvt\nRJ77aDvf/sIgunXMoqK6lsrqEN07Z5PdiuHAZrbMOTcm4XrNCPdxwK+ccxd7r6d4DbkvYp3Z3jof\nm1kWsBfo6+JsPN3Cvb7UyprYY7Vb46UlO5ny2hqW3fEVXly8k2nvb2PZHRfxj9xd9O7agXHDTqRn\nl+yGD8YD3zyDpxZu472fTQDCXzILNhby+3c197eI383/+YTjnhgtmeF+FXCJc+4G7/V3gHOdc9+P\nWGett06+93qrt07MU9PpFu7posy74fYJnbJjrlNaVcMTC7bygy9/luzMDI7U1rF8x0G2Fh3mG6MG\nciQU4nBVLZ2yM+naMYvsTGNvSRU9OmdTUR1ib2kVzsG8vH0Ulh3hhguGsutAJR9v3c/zH+/gguF9\n2F5cTsWREHdfOZLF2w4w/rN9uOlvywBYNOXfWLipiBeX7GSlN+793q9/nttfX0vHrHA9AGOG9CJ3\nh/7HIRLN8c65lMxw/xZwcZNwH+uc+0HEOuu8dSLDfaxzrrjJtm4EbgQYPHjwOTt27GhZqyTtlFTW\nUFUTol/3Tg3LakN1VNaEGr6gakN11Na5hlEqLeWco7w6RKesjIaTjaE6R4aF+0D3HKqkojrEZz/T\nreGkZmaGcbC8ms9E1FVSUcPBimo+KS6nR+dsPvuZbpRU1JB/sJKTe3aits7RITODjlkZvLwsn5sv\nPIXqUB2b9pVxqKKGk3p0YnDvLpRV1fLxtmKqakIM69MVMyPDwpelD+7dlaF9utCzSwfeWbuXyuoQ\nXTpmctkZ/enXvRPLdx7k9P7dWbu7hHl5hVz3xRzuezuPswb2ZNv+csafciI7D1Q0GlU0qHdnDlfV\n8pOLPsfUN9cxoGdnLj+zPyMH9OCDzUU4By8vy+e0k05gw94yLhjeh+6ds1mdf4hhfbrRq0t2w8Vj\nmRnGlWefzOsrdh8zfPHUfiewcV9ZzL+HzAzTvYKTJF2O3D8V3TIiIn7Q3HBvTq/+UmC4mQ01sw7A\nJGBGk3VmANd5z68C3osX7CIi0rYSnjl0ztWa2feB2YSHQj7rnFtnZr8Gcp1zM4BngL+a2RbgAOEv\nABERSZFmDQtxzs0CZjVZNjXieRXwreSWJiIixyuQc8uIiHzaKdxFRAJI4S4iEkAKdxGRAFK4i4gE\nUMKLmNpsx2ZFwPFeotoHCMKs+0FoRxDaAMFoRxDaAMFoR1u2YYhzLuH0tikL99Yws9zmXKGV7oLQ\njiC0AYLRjiC0AYLRjnRog7plREQCSOEuIhJAfg33aakuIEmC0I4gtAGC0Y4gtAGC0Y6Ut8GXfe4i\nIhKfX4/cRUQkDt+Fu5ldYmYbzWyLmU1OdT2RzOxZMyv07kxVv6y3mc0xs83eYy9vuZnZY147VpvZ\n6Ijfuc5bf7OZXRdtX23cjkFmNt/M8sxsnZn9yG9tMbNOZrbEzFZ5bbjbWz7UzBZ79Uz3prHGzDp6\nr7d47+dEbGuKt3yjmV3cXm2I2H+mma0ws7d83IbtZrbGzFaaWa63zDefp4j99zSzV8xsg/fvY1za\ntsM555sfwlMObwWGAR2AVcCIVNcVUd+XgNHA2ohlvwMme88nAw94zycCbwMGnAcs9pb3BrZ5j728\n573auR39gdHe8xMI3yB9hJ/a4tXSzXueDSz2avsHMMlb/iRws/f8FuBJ7/kkYLr3fIT3OesIDPU+\nf5nt/PfxU+BF4C3vtR/bsB3o02SZbz5PETU/D9zgPe8A9EzXdrTbH0qS/mDHAbMjXk8BpqS6riY1\n5tA43DcC/b3n/YGN3vOngGuargdcAzwVsbzReilq05vARX5tC9AFWA6cS/jCkqymnyfC9ysY5z3P\n8tazpp+xyPXaqfaBwDzgy8BbXk2+aoO3z+0cG+6++jwB3YFP8M5Vpns7/NYtMwDYFfE631uWzvo5\n5woAvMfPeMtjtSWt2uj9134U4SNfX7XF685YCRQCcwgfsR5yztVGqaehVu/9EuBEUv/38QjwC6DO\ne30i/msDgAPeNbNlFr6XMvjs80S4x6AI+LPXTfa0mXUlTdvht3C3KMv8OtwnVlvSpo1m1g14Ffix\nc6403qpRlqW8Lc65kHPubMJHv2OB0+PUk3ZtMLPLgULn3LLIxXHqSbs2RBjvnBsNXArcamZfirNu\nurYji3C36xPOuVFAOeFumFhS2g6/hXs+MCji9UBgT4pqaa59ZtYfwHss9JbHaktatNHMsgkH+wvO\nude8xb5si3PuELCAcL9nTwvfxL1pPQ21eu/3IHzLyFS2YTxwhZltB/5OuGvmEfzVBgCcc3u8x0Lg\ndcJftn77POUD+c65xd7rVwiHfVq2w2/h3pybdaebyJuHX0e4/7p++bXeGfXzgBLvv3Szga+aWS/v\nrPtXvWXtxsyM8H1x85xzD0W85Zu2mFlfM+vpPe8MfAXIA+YTvol7tDZEu8n7DGCSNxJlKDAcWNIe\nbXDOTXHODXTO5RD+rL/nnPt3P7UBwMy6mtkJ9c8Jfw7W4qPPE4Bzbi+wy8xO9Rb9G7A+bdvRnidV\nknRSYyLh0RtbgdtTXU+T2l4CCoAawt/O3yPc5zkP2Ow99vbWNeCPXjvWAGMitvNdYIv3c30K2nE+\n4f8mrgZWej8T/dQW4ExghdeGtcBUb/kwwsG2BXgZ6Ogt7+S93uK9PyxiW7d7bdsIXJqiz9YEjo6W\n8VUbvHpXeT/r6v/d+unzFLH/s4Fc73P1BuHRLmnZDl2hKiISQH7rlhERkWZQuIuIBJDCXUQkgBTu\nIiIBpHAXEQkghbuISAAp3EVEAkjhLiISQP8LCyEhnFKy+0wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2909f0ed68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.99987804878\n",
      "Test accuracy: 0.968\n"
     ]
    }
   ],
   "source": [
    "# step 1: get the data and define all the usual variables\n",
    "X, Y = get_normalized_data()\n",
    "# Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.03)\n",
    "X, Y = shuffle(X, Y)\n",
    "Xtrain, Ytrain = X[:-1000], Y[:-1000]\n",
    "Xtest, Ytest = X[-1000:], Y[-1000:]\n",
    "\n",
    "ann = ANN([500, 300])\n",
    "\n",
    "session = tf.InteractiveSession()\n",
    "ann.set_session(session)\n",
    "\n",
    "ann.fit(Xtrain, Ytrain, Xtest, Ytest, show_fig=True)\n",
    "\n",
    "print(\"Train accuracy:\", ann.score(Xtrain, Ytrain))\n",
    "print(\"Test accuracy:\", ann.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
